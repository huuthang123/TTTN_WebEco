import fasttext
from pymongo import MongoClient
from datetime import datetime
from collections import Counter
from bson import ObjectId
import re

# ======================
# CONFIG
# ======================
MONGO_URI = "mongodb+srv://ngthang0311:Huuthang123@cluster0.o4wdz.mongodb.net/WebEcommerceTTTN?retryWrites=true&w=majority&appName=Cluster0"
DB_NAME = "WebEcommerceTTTN"
FASTTEXT_MODEL_PATH = "data/fasttext/en.bin"

# ======================
# K·∫æT N·ªêI MONGODB
# ======================
client = MongoClient(MONGO_URI)
db = client[DB_NAME]
reviews_col = db["reviews"]
summaries_col = db["productsummaries"]  # ƒë√∫ng t√™n collection c·ªßa schema

# ======================
# LOAD FASTTEXT MODEL
# ======================
print("üîÑ Loading FastText model...")
model = fasttext.load_model(FASTTEXT_MODEL_PATH)
print("‚úÖ FastText model loaded.")

# ======================
# H√ÄM L·ªåC T·ª™
# ======================
def preprocess_text(text):
    """T√°ch t·ª´ v√† lo·∫°i k√Ω t·ª± ƒë·∫∑c bi·ªát, gi·ªØ nguy√™n lowercase"""
    return re.findall(r'\b[a-z]+\b', text.lower())

# ======================
# H√ÄM T√ìM T·∫ÆT REVIEW (lo·∫°i c√¢u tr√πng)
# ======================
def summarize_reviews(reviews):
    if not reviews:
        return ""

    # Gh√©p t·∫•t c·∫£ review
    text = " ".join(reviews)
    sentences = [s.strip() for s in text.split(".") if s.strip()]
    if not sentences:
        return ""

    # T√≠nh vector cho t·ª´ng c√¢u
    sentence_vectors = [model.get_sentence_vector(s) for s in sentences]
    avg_vector = sum(sentence_vectors) / len(sentence_vectors)

    def cosine_similarity(v1, v2):
        return sum(a*b for a, b in zip(v1, v2)) / (
            (sum(a*a for a in v1) ** 0.5) * (sum(b*b for b in v2) ** 0.5)
        )

    # Ch·∫•m ƒëi·ªÉm v√† s·∫Øp x·∫øp
    scored_sentences = [
        (s, cosine_similarity(model.get_sentence_vector(s), avg_vector))
        for s in sentences
    ]
    scored_sentences.sort(key=lambda x: x[1], reverse=True)

    # Lo·∫°i b·ªè c√¢u tr√πng l·∫∑p (case-insensitive)
    seen = set()
    summary_sentences = []
    for s, _ in scored_sentences:
        key = s.lower()
        if key not in seen:
            seen.add(key)
            summary_sentences.append(s)
        if len(summary_sentences) >= 3:
            break

    return ". ".join(summary_sentences).strip()

# ======================
# X·ª¨ L√ù TO√ÄN B·ªò S·∫¢N PH·∫®M
# ======================
product_ids = reviews_col.distinct("productId")
print(f"üîç Found {len(product_ids)} products to summarize.")

for pid in product_ids:
    try:
        # L·∫•y t·∫•t c·∫£ review (comment)
        reviews = [r["comment"] for r in reviews_col.find({"productId": pid}) if r.get("comment")]
        total_reviews = len(reviews)
        if total_reviews == 0:
            continue

        # Sinh t√≥m t·∫Øt
        summary = summarize_reviews(reviews)

        # T√≠nh t·∫ßn su·∫•t t·ª´
        all_words = []
        for review in reviews:
            all_words.extend(preprocess_text(review))
        word_freq = dict(Counter(all_words))

        # L∆∞u v√†o DB theo schema ProductSummary
        summaries_col.update_one(
            {"productId": ObjectId(pid)},
            {
                "$set": {
                    "summary": summary,
                    "wordFreq": word_freq,
                    "lastUpdated": datetime.utcnow(),
                    "totalReviews": total_reviews
                }
            },
            upsert=True
        )

        print(f"‚úÖ Summarized product {pid} ({total_reviews} reviews)")

    except Exception as e:
        print(f"‚ùå Error with product {pid}: {e}")

print("üéØ All summaries created successfully.")
